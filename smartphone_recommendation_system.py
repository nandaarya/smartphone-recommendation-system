# -*- coding: utf-8 -*-
"""smartphone-recommendation-system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bSyd3anv7iS8WGY3LYLIRMUKUpWiMAcA

# **Smartphone Recommendation System**

**Description** : Proses pembuatan model untuk rekomendasi smartphone

**Dataset** : https://www.kaggle.com/datasets/abdulmalik1518/mobiles-dataset-2025 & https://www.kaggle.com/datasets/ireddragonicy/antutu-benchmark

**Model** : Weight Sum Model (WSM) & Learning to Rank (LTR)

# **Data Loading**

Pada bagian ini, langkah pertama adalah membaca dataset secara langsung dari folder dataset "Mobiles Dataset (2025)" yang sudah di download melalui Kaggle. Dataset yang digunakan adalah Mobiles Dataset (2025).csv yang berisi dataset untuk proses pelatihan model. Tetapi karena kolom processor hanya berupa nama processor, akan digunakan dataset tambahan (Android_SoC.csv dan iOS_Performance.csv) dari antutu benchmark untuk mengubah nilai processor menambahkan data hasil benchmark dari setiap processor sebagai representasi kemampuan setiap processor. Data di transformasi secara dasar tanpa penambahan atau pengurangan data sebagai persiapan untuk Exploratory Data Analysis (EDA).
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import os
import re

"""## **Dataset 1**

Load Mobiles Dataset (2025).csv Dataset
"""

# Path to file
file_path = "/kaggle/input/mobiles-dataset-2025/Mobiles Dataset (2025).csv"

# Load dataset ke Pandas DataFrame
df1 = pd.read_csv(file_path, encoding="ISO-8859-1")

df1.head()

print(df1["Processor"].unique())

"""Ada data Processor yang tidak konsisten dan harus dilakukan mapping untuk memperbaikinya."""

def remove_selected_brands(processor):
    return re.sub(r"^(Apple|Samsung|Qualcomm|MediaTek|HiSilicon|Google)\s+", "", processor)

df1["Processor"] = df1["Processor"].apply(remove_selected_brands)

# Clean 4G / 5G Word
def normalize_processor_name(processor):
    return re.sub(r"\s+(?:5G|4G)$", "", processor)

df1["Processor"] = df1["Processor"].apply(normalize_processor_name)

# Mapping inconsistent name
processor_mapping = {
    "Snapdragon 7 Plus Gen 3": "Snapdragon 7+ Gen 3",
    "Dimensity 8000-Max": "Dimensity 8000",
    "Dimensity 7025-Ultra": "Dimensity 7025",
    "Snapdragon 6s 4G Gen 1": "Snapdragon 6 Gen 1",
    "Snapdragon 6s Gen 1": "Snapdragon 6 Gen 1",
    "Snapdragon 7s Gen 1": "Snapdragon 7 Gen 1",
    "Snapdragon 6s Gen 3": "Snapdragon 6 Gen 3",
    "Dimensity 1200-AI": "Dimensity 1200",
    "Dimensity 1300T": "Dimensity 1300",
    "Kirin 710F": "Kirin 710",
    "G35": "Helio G35",
    "G99": "Helio G99",
    "MT6762G Helio G25": "Helio G25",
    "Helio P22T": "Helio P22",
    "Dimensity 8300-Ultra": "Dimensity 8300"
}

df1["Processor"] = df1["Processor"].replace(processor_mapping)

print(df1["Processor"].unique())

"""Data kolom processor diatas sudah diperbaiki"""

df1.info()

"""Diatas adalah stuktur dataset pertama.

## **Dataset 2**
Load Android_SoC.csv Dataset
"""

file_path = "/kaggle/input/antutu-benchmark/Android_SoC.csv"

df2 = pd.read_csv(file_path)
pd.set_option('display.max_colwidth', None)

df2.head()

"""Kolom Device yang merepresentasikan nama processor memiliki format yang tidak beraturan dan perlu di bersihkan terlebih dahulu"""

# Clean Device Column Data to display only processor name
df2["Device"] = df2["Device"].astype(str)
df2["Device"] = df2["Device"].str.replace(r"\s+", " ", regex=True).str.strip()
df2["Device"] = df2["Device"].str.extract(r'([^\(]+)')[0].str.strip()
df2["Device"] = df2["Device"].str.replace(r'^\d+\s+', '', regex=True)

def remove_selected_brands(processor):
    return re.sub(r"^(Apple|Samsung|Qualcomm|MediaTek|HiSilicon|Google)\s+", "", processor)

df2["Device"] = df2["Device"].apply(remove_selected_brands)

# Clean 4G / 5G Word
def normalize_processor_name(processor):
    return re.sub(r"\s+(?:5G|4G)$", "", processor)

df2["Device"] = df2["Device"].apply(normalize_processor_name)

# Mapping inconsistent name
processor_mapping = {
    "Dimensity 8200/8200 Ultra": "Dimensity 8200",
    "Kirin 9000S1": "Kirin 9000S",
    "Dimensity 8350 Ultimate": "Dimensity 8350",
    "Snapdragon 888 Plus": "Snapdragon 888+",
    "Snapdragon 480 Plus": "Snapdragon 480+",
    "Dimensity 8400-Max": " Dimensity 8400",
    "Snapdragon 778G Plus": "Snapdragon 778G+",
    " Dimensity 8400": "Dimensity 8400",
    "Dimensity 8300-Ultra": "Dimensity 8300"
}

df2["Device"] = df2["Device"].str.strip()
df2["Device"] = df2["Device"].replace(processor_mapping)
df2["Device"] = df2["Device"].str.strip()

df2.head()

"""Kolom device diatas sudah diperbaiki."""

df2.info()

"""Diatas adalah stuktur dataset kedua.

## Dataset Merger
Penggambungan Kedua Dataset sebelumnya menggunakan kolom "Processor" dalam dataset 1 dan kolom "Device" dalam dataset 2 sebagai primary key. Kedua kolom tersebut sama-sama menyatakan nama processor. Kolom Total Score diambil dari dataset 2 dan digabungkan ke dataset 1. Hanya Total Score yang diambil karena sudah mewakili CPU Score + GPU Score.
"""

# Merge df1 with df2 based Processor and Device
df = df1.merge(df2[["Device", "Total Score"]], left_on="Processor", right_on="Device", how="left")

# Rename Total Score to Performance Score
df.rename(columns={"Total Score": "Performance Score"}, inplace=True)
df.drop(columns=["Device"], inplace=True)

df.head()

"""Setelah menggabungkan dataset, akan dilakukan data transformation tanpa menambah atau menghapus data sebagai persiapan Exploratory Data Analysis (EDA)"""

# Data transformation, preparation for Exploratory Data Analysis (EDA)
df["Company Name"] = df["Company Name"].str.lower()
df["Mobile Weight"] = df["Mobile Weight"].str.replace("g", "").astype(float)
df["RAM"] = df["RAM"].apply(lambda x: "12GB" if "8GB / 12GB" in x else x)
df["RAM"] = df["RAM"].str.replace("GB", "").astype(float)
df["Front Camera"] = df["Front Camera"].apply(lambda x: max(map(float, re.findall(r"\d+\.\d+|\d+", x))) if pd.notna(x) else None)
df["Back Camera"] = df["Back Camera"].apply(lambda x: max(map(float, re.findall(r"\d+\.\d+|\d+", x))) if pd.notna(x) else None)
df["Battery Capacity"] = df["Battery Capacity"].str.replace(",", "").str.replace("mAh", "").astype(float)
df["Screen Size"] = df["Screen Size"].apply(lambda x: max(map(float, re.findall(r"\d+\.\d+|\d+", x))) if pd.notna(x) else None)
df["Launched Price (Pakistan)"] = pd.to_numeric(
    df["Launched Price (Pakistan)"]
    .replace("Not available", np.nan)
    .str.replace(",", "")
    .str.replace("PKR", ""),
    errors="coerce"
)
df["Launched Price (India)"] = df["Launched Price (India)"].str.replace(",", "").str.replace("INR", "").astype(float)
df["Launched Price (China)"] = df["Launched Price (China)"].str.replace("¥", "").str.replace(",", "").str.replace("CNY", "").astype(float)
df["Launched Price (USA)"] = df["Launched Price (USA)"].str.replace(",", "").str.replace("USD", "").astype(float)
df["Launched Price (Dubai)"] = df["Launched Price (Dubai)"].str.replace(",", "").str.replace("AED", "").astype(float)

df = df.rename(columns={
    "Mobile Weight": "Mobile Weight (g)",
    "RAM": "RAM (GB)",
    "Front Camera": "Front Camera (MP)",
    "Back Camera": "Back Camera (MP)",
    "Battery Capacity": "Battery Capacity (mAh)",
    "Screen Size": "Screen Size (inches)",
    "Launched Price (Pakistan)": "Launched Price (Pakistan/PKR)",
    "Launched Price (India)": "Launched Price (India/INR)",
    "Launched Price (China)": "Launched Price (China/CNY)",
    "Launched Price (USA)": "Launched Price (USA/USD)",
    "Launched Price (Dubai)": "Launched Price (Dubai/AED)"
})

df.head()

"""Data diatas telah ditransformasi tanpa pengubahan nilai untuk proses EDA.

# Exploratory Data Analysis (EDA)

Setelah mendapatkan dataset, proses selanjutnya adalah melakukan Exploratory Data analysis (EDA). EDA adalah proses analisis awal pada suatu dataset untuk memahami karakteristik, distribusi, pola, serta hubungan antar variabel sebelum dilakukan pemodelan. EDA bertujuan untuk menemukan missing values, outlier, distribusi data, serta korelasi antar fitur, sehingga dapat menentukan langkah preprocessing yang tepat.

Dalam EDA, teknik yang sering digunakan meliputi statistik deskriptif (mean, median, standar deviasi), visualisasi data (histogram, boxplot, scatter plot), serta analisis korelasi antar variabel. Dengan melakukan EDA, kita dapat mengidentifikasi potensi masalah dalam dataset dan melakukan penyesuaian yang diperlukan agar model machine learning dapat bekerja secara optimal.

## Deskripsi Variabel
"""

df.info()

"""Hal yang pertama dilakukan adalah menganalisa struktur dataset. Dari output diatas, dapat disimpulkan:

Dataset ini berisi 930 data ponsel dengan 16 fitur yang mencakup informasi mengenai spesifikasi perangkat, harga peluncuran, serta tahun rilisnya. Berikut adalah penjelasan setiap fitur dalam dataset:

1. Company Name (object) – Nama perusahaan atau merek produsen ponsel, seperti Apple, Samsung, Xiaomi, Oppo.
2. Model Name (object) – Nama model spesifik dari ponsel, seperti iPhone 16 128GB, Galaxy S24 Ultra, Redmi Note 12 Pro.
3. Mobile Weight (g) (float64) – Berat ponsel dalam gram, yang mempengaruhi kenyamanan dalam penggunaan.
4. RAM (GB) (float64) – Kapasitas RAM dalam gigabyte (GB), yang berpengaruh pada performa multitasking.
5. Front Camera (MP) (float64) – Resolusi kamera depan dalam megapiksel (MP), yang menentukan kualitas selfie dan panggilan video.
6. Back Camera (MP) (float64) – Resolusi kamera belakang tertinggi dalam megapiksel (MP), yang berpengaruh pada hasil fotografi utama.
7. Processor (object) – Jenis atau seri prosesor yang digunakan, seperti A17 Bionic, Snapdragon 8 Gen 2, MediaTek Dimensity.
8. Battery Capacity (mAh) (float64) – Kapasitas baterai dalam miliampere-jam (mAh), yang mempengaruhi daya tahan pemakaian ponsel.
9. Screen Size (inches) (float64) – Ukuran layar dalam inci, yang berpengaruh pada pengalaman visual pengguna.
10. Launched Price (Pakistan/PKR) (float64) – Harga peluncuran ponsel dalam mata uang Rupee Pakistan (PKR). Beberapa data memiliki nilai yang hilang (missing values).
11. Launched Price (India/INR) (float64) – Harga peluncuran ponsel dalam mata uang Rupee India (INR).
12. Launched Price (China/CNY) (float64) – Harga peluncuran ponsel dalam mata uang Yuan China (CNY).
13. Launched Price (USA/USD) (float64) – Harga peluncuran ponsel dalam mata uang Dolar Amerika Serikat (USD).
14. Launched Price (Dubai/AED) (float64) – Harga peluncuran ponsel dalam mata uang Dirham Uni Emirat Arab (AED).
15. Launched Year (int64) – Tahun peluncuran ponsel, yang menunjukkan periode rilis dari perangkat tersebut.
16. Performance Score - Skor performa smartphone dinilaid dari processor/SoC berdasarkan data Antutu Benchmark

Dari daftar fitur di atas, harga dalam berbagai mata uang dapat digunakan sebagai variabel target dalam pemodelan sistem rekomendasi, sedangkan fitur spesifikasi ponsel berperan sebagai variabel independen yang digunakan untuk menentukan rekomendasi terbaik bagi pengguna.
"""

df.describe()

"""Dari output diatas, dapat diambil beberapa kesimpulan:

1. **Tahun Peluncuran (Launched Year)**: Rentang tahun berkisar antara **2014 hingga 2025**.
2. **Harga Peluncuran (Launched Price)**:
   - Harga sangat bervariasi di berbagai negara.
   - Rentang harga mulai dari **PKR 15,999 hingga PKR 604,999** dan **USD 79 hingga USD 39,622**.
   - Rentang harga ini menunjukkan adanya **perbedaan kelas perangkat**, tetapi juga kemungkinan **outlier** yang perlu dianalisis lebih lanjut.
3. **Ukuran Layar (Screen Size)**: Berkisar antara **5.0 hingga 14.6 inci**.
4. **Kapasitas Baterai (Battery Capacity)**:
   - Rentang antara **2000 hingga 11,200 mAh**.
   - Variasi besar ini menunjukkan kemungkinan adanya **perangkat dengan kapasitas ekstrem**, seperti tablet atau rugged phone.
5. **RAM**:
   - Berkisar antara **1 GB hingga 16 GB**.
   - Ini mencerminkan berbagai kategori ponsel, dari **entry-level hingga flagship**.
6. **Kamera**:
   - Kamera depan berkisar antara **2 MP hingga 60 MP**.
   - Kamera belakang berkisar antara **5 MP hingga 200 MP**.
7. **Bobot Perangkat (Mobile Weight)**:
   - Rata-rata bobot perangkat adalah **228 gram**.
   - Nilai maksimum **732 gram** jauh di atas rata-rata, kemungkinan berasal dari **perangkat foldable atau rugged phone**.
8. **Performance Score**:
   - Nilai berkisar antara **25,673 hingga 1,709,461**.
   - Ini menunjukkan perbedaan besar antara perangkat **entry-level dan flagship terbaru**.
9. **Missing Values**:
   - Terdapat **satu missing value** pada **harga peluncuran di Pakistan (Launched Price Pakistan/PKR)**.
   - Perlu dilakukan **pemeriksaan lebih lanjut dan penanganan** terhadap data yang hilang.
"""

df.shape

"""## Univariate Analysis

Selanjutnya adalah melakukan Univariate Analysis. Univariate Analysis adalah analisis statistik yang dilakukan pada satu fitur untuk memahami karakteristik dan distribusi datanya. Metodenya menggunakan visualisasi agar mudah mendeteksi pola data dan sebaran nilainya.

Fitur numerik dalam dataset meliputi **Mobile Weight (g), RAM (GB), Front Camera (MP), Back Camera (MP), Battery Capacity (mAh), Screen Size (inches), Launched Price (Pakistan/PKR), Launched Price (India/INR), Launched Price (China/CNY), Launched Price (USA/USD), Launched Price (Dubai/AED), dan Launched Year**, yang merepresentasikan nilai kontinu.

Sementara itu, fitur kategorikal terdiri dari Company Name, Model Name, dan Processor, yang berisi nilai dalam bentuk kategori atau label.
"""

numerical_features = [
    "Mobile Weight (g)", "RAM (GB)", "Front Camera (MP)", "Back Camera (MP)",
    "Battery Capacity (mAh)", "Screen Size (inches)",
    "Launched Price (Pakistan/PKR)", "Launched Price (India/INR)",
    "Launched Price (China/CNY)", "Launched Price (USA/USD)",
    "Launched Price (Dubai/AED)", "Launched Year", "Performance Score"
]

categorical_features = [
    "Company Name", "Model Name", "Processor"
]

"""### Categorical Features"""

for feature in categorical_features:
    count = df[feature].value_counts()
    percent = 100 * df[feature].value_counts(normalize=True)

    df_summary = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
    print(f"\nDistribusi data untuk {feature}:\n", df_summary)

    plt.figure(figsize=(10, 5))
    count.plot(kind='bar', title=f'Distribusi {feature}')
    plt.xlabel(feature)
    plt.ylabel('Jumlah Sampel')
    plt.xticks(rotation=45)
    plt.show()

"""Dari visualisasi distribusi data fitur-fitur kategorikal di atas dapat disimpulkan bahwa:

* Fitur Company Name: Oppo merupakan merek dengan jumlah ponsel terbanyak (13.9%), diikuti oleh Apple (10.4%) dan Honor (9.8%). Merek seperti iQOO (0.3%) dan Sony (1.0%) memiliki jumlah sampel paling sedikit.
* Fitur Model Name: Dataset memiliki 908 model unik, dengan sebagian besar model hanya memiliki 1 atau 2 sampel. Hal ini menunjukkan bahwa dataset sangat bervariasi dalam hal model ponsel.
* Fitur Processor: Snapdragon 8 Gen 2 (3.2%) adalah prosesor yang paling umum digunakan, diikuti oleh MediaTek Dimensity 810 (2.4%) dan Helio G99 (2.3%). Namun, ada 217 jenis prosesor berbeda, dengan banyak prosesor hanya memiliki 1 sampel, menunjukkan variasi yang luas dalam jenis chipset yang digunakan.
* Distribusi Model & Processor: Banyak model dan prosesor memiliki jumlah sampel yang sangat sedikit, menunjukkan bahwa dataset mencakup berbagai varian ponsel dengan spesifikasi yang beragam.

### Numerical Features
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari visualisasi distribusi data fitur-fitur numerik diatas dapat disimpulkan bahwa:
* Mobile Weight (g)
  * Sample terbanyak ada di value Mobile Weight sekitar 190g
  * Tidak ada pola khusus, tetapi sample terpusat di 190g, sisanya lebih dan kurang dari 190g.

* RAM (GB)
  * Sample terbanyak ada di value RAM 8 GB.
  * Ram dengan sample terbanyak selanjutnya adalah 4, 6, 12 GB.
  
* Front Camera (MP)
  * Sample terbanyak ada di value 8, 17, 32 MP.
  * Tidak ada pola khusus pada data.

* Back Camera (MP)
  * Sample terbanyak ada di value 50 MP.
  * Tidak ada pola khusus pada data.

* Batery Capacity (mAh)
  * Sample terbanyak ada di value 5000 mAh.
  * Lebih dari 50% sample memiliki value 5000 mAh dan dibawahnya.
  * Tidak ada pola khusus pada data.

* Screen Sizes (Inches)
  * Tidak ada pola khusus dalam distribusi.
  * Data terpusat di sekitar value 6.8 inches.

* Launched Price (Pakistan/PKR), Launched Price (India/INR), Launched Price (China/CNY), Launched Price (USA/USD), Launched Price (Dubai/AED)
  * Beberapa fitur diatas memiliki kesamaan pola dimana semakin tinggi harganya maka jumlah sample semakin sedikit.
  * Distribusi mileage miring ke kanan.

* Launched Year
  * Jumlah sample terbanyak ada di value 2024.
  * Distribusi mileage miring ke kiri.

* Performance Score
  * Tidak ada pola khusus yang terlihat
  * Lebih dari 50% sample memiliki skor kurang dari 0.5 x le6

## Multivariate Analysis

Langkah selanjutnya adalah melakukan Multivariate Analysis. Multivariate Analysis adalah teknik analisis statistik yang digunakan untuk memahami hubungan antara dua atau lebih variabel dalam suatu dataset. Tujuan utama analisis ini adalah untuk mengidentifikasi pola, hubungan, atau korelasi antara fitur, sehingga dapat membantu dalam pemodelan prediktif dan pengambilan keputusan. Fitur **Launched Price (China/CNY)** dipilih sebagai target analisis korelasi karena China adalah produsen terbesar smartphone terbesar didunia.

### Categorical Features
"""

cat_features = df.select_dtypes(include='object').columns.to_list()

# We use Launched Price (China/CNY) to see corelation between price and feature
for col in cat_features:
  sns.catplot(x=col, y="Launched Price (China/CNY)", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'Launched Price (China/CNY)' Relatif terhadap - {}".format(col))

"""Dari catplot visualisasi hubungan antara fitur price dengan fitur-fitur kategorikal diatas dapat disimpulkan bahwa:
* Pada fitur ‘Company Name’, ada perbedaan rata-rata harga. beberapa company name yaitu apple, huawei, sony, dan google memiliki rata-rata harga yang lebih tinggi daripada brand lainnya. Sehingga kemungkinan fitur company name memiliki pengaruh atau dampak yang cukup besar terhadap rata-rata harga.
* Pada fitur ‘Model’, ada banyak kategori dan tidak banyak perbedaan rata-rata harga. Hanya ada beberapa model yang memiliki perbedaan harga yang signifikan. Sehingga kemungkinan fitur brand memiliki pengaruh atau dampak yang cukup kecil terhadap rata-rata harga.
* Pada fitur ‘Processor’, ada banyak kategori dan tidak banyak perbedaan rata-rata harga. Hanya ada beberapa processor yang memiliki perbedaan harga yang signifikan. Sehingga kemungkinan fitur brand memiliki pengaruh atau dampak yang cukup kecil terhadap rata-rata harga.

### Numerical Features
"""

sns.pairplot(df, diag_kind = 'kde')

"""Dari grafik pairplot diatas, jika fokus pada sumbu "Launched Price (China/CNY)" dimana merupakan fitur target, dapat disimpulkan bahwa:

* Fitur mobile weight (g), Battery Capacity, dan Screen Size memiliki korelasi positif dengan fitur Launched Price (China/CNY) walaupun tidak terlalu terlihat.
* Fitur Performance Score memiliki korelasi positif dengan fitur Launched Price (China/CNY).
* Fitur RAM, Front Camera, Back Camera, dan Launched Year memiliki pola yang cukup acak dengan fitur Launched Price (China/CNY).
* Fitur yang tersisa, Launched Price (Pakistan/PKR), Launched Price (India/INR), Launched Price (USA/USD), dan Launched Price (Dubai/AED) tidak memiliki korelasi dengan fitur Launched Price (China/CNY) karena sebenarnya fitur-fitur tersebut sama-sama merepresentasikan harga, hanya dalam daerah atau mata uang yang berbeda.
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Untuk lebih jelasnya, dapat diamati grafik korelasi diatas. Dapat disimpulkan bahwa:

* Hanya fitur RAM yang memiliki korelasi yang cukup kuat (0.43) dengan Launched Price (China/CNY), Kecuali fitur Launched Price negara lain.
* Fitur Mobile Weight memiliki korelasi yang sangat kuat (0.98) dengan Screen Size (Inches) dan korelasi kuat (0.85) dengan Battery Capacity.
* Fitur Battery Capacity memiliki korelasi yang kuat (0.88) dengan Screen Size (Inches).
* Fitur Performance score memiliki korelasi yang cukup kuat (0.67) dengan Launched Price (China/CNY) dan korelasi yang cukup kuat (0.7) dengan fitur RAM.

# **Data Preparation**

Setelah melakukan EDA dan sebelum membangun model machine learning, diperlukan tahapan data preparation untuk memastikan bahwa data memiliki kualitas yang baik dan dapat meningkatkan performa model. Tahapan ini mencakup pembersihan data, transformasi fitur, encoding variabel kategorikal, reduksi dimensi, serta standarisasi fitur.
"""

df.info()

"""Diatas adalah struktur dataset yang masih seperti awal. memiliki 16 fitur."""

df.drop(columns=["Launched Price (Pakistan/PKR)", "Launched Price (India/INR)",
                 "Launched Price (USA/USD)", "Launched Price (Dubai/AED)",
                 "Processor"], inplace=True)
df.head()

"""Lalu dilakukan proses data preparation yang pertama, yaitu menghapus fitur yang dianggap tidak diperlukan dalam membuat sistem rekomendasi.

* Fitur "Launched Price (Pakistan/PKR)", "Launched Price (India/INR)", "Launched Price (USA/USD)", dan "Launched Price (Dubai/AED)" dihapus karena sudah ada fitur Launched Price (China/CNY) yang merepresentasikan harga berdasarkan negara atau mata uang China/CNY.
* Fitur Processor sudah tidak diperlukan karena sudah ada fitur Performance Score yang merepresentasikan kemampuan processor smartphone.
"""

df.info()

"""Setelah dilakukan penghapusan, diatas adalah struktur dataset yang baru dengan kolom "Launched Price (Pakistan/PKR)", "Launched Price (India/INR)", "Launched Price (USA/USD)", "Launched Price (Dubai/AED)", dan "Processor" yang sudah tidak ada."""

# Check Missing Values
df.isnull().sum()

"""Kode diatas berfungsi untuk melihat apakah ada missing values pada dataset. Setelah dijalankan, ternyata pada kolom performance score terdapat 135. Hal ini mungkin dikarenakan kurang lengkapnya dataset kedua yang sebelumnya digabungkan, sehingga ada data yang kosong."""

# Count missing values in "Performance Score" column by Company Name
missing_values_performance = df.groupby("Company Name")["Performance Score"].apply(lambda x: x.isnull().sum())

print(missing_values_performance)

"""Dari kode diatas, ternyata sebagian besar missing values ada di device Apple. Hal ini mungkin dikarenakan dataset 2 yang telah diganbungkan hanya memiliki data benchmark performance untuk processor/SoC Android.

## Menangani Missing Values & Outliers

Langkah kedua dalam data preparation adalah menangani Missing Values & Outliers.

* Dari kode sebelumnya, terdapat banyak missing values di device Apple sehingga diputuskan untuk menghapus data dengan missing values dan tidak dilakukan imputasi demi menjaga relevansi dan validitas data kolom Performance Score karena sangat penting.
* Metode yang digunakan untuk menangani outliers adalah **Box-Cox Transformation**.

Box-Cox Transformation adalah teknik yang digunakan untuk menormalkan distribusi data dan mengurangi pengaruh outliers dengan menerapkan transformasi non-linear pada fitur numerik yang hanya memiliki nilai positif.

Alasan Pemilihan Box-Cox:
* Mengatasi Outliers Tanpa Menghapus Data → Tidak ada informasi yang hilang, hanya ditransformasikan.
* Membantu Menormalkan Data → Berguna untuk model berbasis regresi dan metode yang mengasumsikan distribusi normal.
* Lebih Efektif Dibanding Log Transformation → Sebelumnya telah dicoba metode Log Transformation dan ternyata Box-Cox lebih baik karena secara dinamis menyesuaikan transformasi berdasarkan distribusi data.
"""

# Delete row with missing values
df = df.dropna(subset=["Performance Score"])

# Check Missing Values
df.isnull().sum()

# Save Original Dataset before transformation
df_original = df.copy()

"""Setelah dilakukan penghapusan, sudah tidak ada lagi missing values pada dataset."""

df.info()

"""Dataset yang tersisa berjumlah 802 data"""

df.describe()

# Box-Plot to visualize outliers
num_features = df.select_dtypes(include=['number']).columns
num_plots = len(num_features)
rows = (num_plots // 4) + (num_plots % 4 > 0)
fig, axes = plt.subplots(nrows=rows, ncols=4, figsize=(15, 4 * rows))
axes = axes.flatten()

for i, feature in enumerate(num_features):
    sns.boxplot(x=df[feature], ax=axes[i])
    axes[i].set_title(feature)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Titik-titik diluar adalah outlier yang perlu diatasi."""

from scipy.stats import boxcox

# Copy dataframe to avoid SettingWithCopyWarning
df = df.copy()

numerical_features = [
    "Mobile Weight (g)", "Back Camera (MP)",
    "Battery Capacity (mAh)", "Screen Size (inches)",
    "Launched Price (China/CNY)", "Performance Score"
]

boxcox_lambdas = {}

# Box-Cox
for feature in numerical_features:
    df.loc[:, feature], boxcox_lambdas[feature] = boxcox(df[feature])

print("Data transformation complete!")

"""Kode diatas adalah kode untuk metode Box-Cox. Untuk mengatasi outliers tanpa mengubah nilai asli atau menghapus data. Informasi akan dipertahankan."""

# Box-Plot to visualize outliers
num_features = df.select_dtypes(include=['number']).columns
num_plots = len(num_features)
rows = (num_plots // 4) + (num_plots % 4 > 0)
fig, axes = plt.subplots(nrows=rows, ncols=4, figsize=(15, 4 * rows))
axes = axes.flatten()

for i, feature in enumerate(num_features):
    sns.boxplot(x=df[feature], ax=axes[i])
    axes[i].set_title(feature)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Setelah dilakukan metode Box-Cox untuk mengatasi, terlihat persebaran data menjadi lebih baik meskipun beberapa fitur masih memiliki outlier.

## Encoding for Categorical Feature

Langkah ketiga adalah encoding untuk fitur kategorikal.

Teknik yang digunakan:
* Target Encoding untuk fitur Company Name
* Label Encoding untuk fitur Model Name

Pada tahap ini, dilakukan encoding untuk fitur kategorikal agar dapat digunakan dalam model machine learning. Teknik yang digunakan adalah Target Encoding untuk fitur Company Name dan Label Encoding untuk fitur Model Name.

* Encoding untuk fitur Company Name
    * Company Name dikonversi ke nilai numerik berdasarkan rata-rata Performance Score dari setiap perusahaan.
    * Teknik ini membantu mempertahankan hubungan antara kategori dengan target tanpa meningkatkan dimensi dataset.
* Encoding untuk fitur Model Name
    * Model Name dikonversi ke nilai numerik menggunakan Label Encoding, di mana setiap model diberikan nilai unik berdasarkan indeksnya.
    * Metode ini digunakan karena jumlah kategori pada Model Name sangat banyak, sehingga One-Hot Encoding tidak efisien dan menyebabkan peningkatan dimensi dataset (curse of dimensionality).
* Alasan Pemilihan Teknik Encoding
    * Target Encoding cocok untuk Company Name, karena dapat menangkap hubungan antara brand dan performa perangkat.
    * Label Encoding cocok untuk Model Name, karena lebih efisien dalam menyimpan informasi tanpa meningkatkan dimensi dataset secara signifikan.
"""

from sklearn.preprocessing import LabelEncoder

# Using Target Encoding for Company Name
company_target_mean = df.groupby("Company Name")["Performance Score"].mean()
df["Company Name Encoded"] = df["Company Name"].map(company_target_mean)

# Mapping for decoding
company_mapping = company_target_mean.to_dict()
reverse_company_mapping = {v: k for k, v in company_mapping.items()}

# Label Encoding for Model Name
label_encoder = LabelEncoder()
df["Model Name Encoded"] = label_encoder.fit_transform(df["Model Name"])

# Mapping for decoding
model_mapping = dict(zip(df["Model Name"], df["Model Name Encoded"]))
reverse_model_mapping = {v: k for k, v in model_mapping.items()}

# Remove original categorical columns
df.drop(columns=["Company Name", "Model Name"], inplace=True)

df.head()

df.describe()

"""## Standarization

Langkah keenam dan terakhir adalah melakukan Standarisasi. Standarisasi adalah proses transformasi data numerik agar memiliki skala yang seragam, biasanya dengan mean (rata-rata) = 0 dan standar deviasi = 1. Tujuannya adalah untuk memastikan bahwa setiap fitur memiliki kontribusi yang seimbang dalam model machine learning, terutama jika fitur memiliki skala atau unit yang berbeda. Teknik yang digunakan adalah Standar Scaler.

Alasan:

* Menghindari skala yang terlalu besar pada fitur tertentu, yang dapat memengaruhi performa model.
"""

from sklearn.preprocessing import StandardScaler

numerical_features = [
    "Mobile Weight (g)", "RAM (GB)", "Front Camera (MP)", "Back Camera (MP)",
    "Battery Capacity (mAh)", "Screen Size (inches)",
    "Launched Price (China/CNY)", "Performance Score", "Launched Year"
]

scaler = StandardScaler()

df[numerical_features] = scaler.fit_transform(df[numerical_features])

df.head()

df.describe().round(4)

"""Setelah dilakukan standarisasi, dapat dilihat pada semua fitur numerik nilai mean (rata-rata) menjadi 0 dan standar deviasi (std) menjadi 1.

# Modelling

Setelah melakukan Data Preparation, selanjutnya adalah melakukan modelling machine learning. Modelling dalam sistem rekomendasi adalah proses membangun metode yang dapat memberikan rekomendasi berdasarkan preferensi dan kebutuhan pengguna. Dalam kasus ini, sistem rekomendasi yang dibuat menggunakan pendekatan **Content-Based Filtering**. Hal ini dikarenakan dataset yang digunakan hanya berisi fitur-fitur mengenai content/item yang berupa spesifikasi smartphone. Model atau algoritma yang digunakan adalah **Weighted Sum Model (WSM)** dan **Learning to Rank (LTR)**.
"""

weight_preferences = {
    "gaming": {
        "Performance Score": 0.6,
        "RAM (GB)": 0.2,
        "Battery Capacity (mAh)": 0.12,
        "Launched Year": 0.08,
        "Screen Size (inches)": 0.005,
        "Back Camera (MP)": 0.002,
        "Front Camera (MP)": 0.001,
        "Mobile Weight (g)": 0.002
    },
    "photography": {
        "Back Camera (MP)": 0.35,
        "Front Camera (MP)": 0.35,
        "RAM (GB)": 0.08,
        "Performance Score": 0.08,
        "Launched Year": 0.10,
        "Screen Size (inches)": 0.03,
        "Battery Capacity (mAh)": 0.02,
        "Mobile Weight (g)": 0.01
    },
    "normal usage": {
        "Battery Capacity (mAh)": 0.30,
        "Performance Score": 0.28,
        "RAM (GB)": 0.15,
        "Mobile Weight (g)": 0.10,
        "Launched Year": 0.12,
        "Screen Size (inches)": 0.03,
        "Back Camera (MP)": 0.015,
        "Front Camera (MP)": 0.005
    }
}

"""Diatas adalah variabel yang menentukan pembobotan tiap fitur yang akan digunakan di kedua model yang akan dibuat.

## Model 1: Weighted Sum Model (WSM)
Weighted Sum Model (WSM) adalah metode berbasis skoring yang digunakan untuk mengurutkan dan memilih alternatif terbaik berdasarkan bobot preferensi pengguna. Dalam sistem rekomendasi smartphone, WSM digunakan untuk menghitung skor total setiap smartphone dengan menjumlahkan nilai fitur yang telah dinormalisasi, dikalikan dengan bobot yang telah ditentukan untuk setiap preferensi pengguna.

Dalam penerapan WSM pada sistem rekomendasi smartphone, setiap smartphone diberi Ranking Score berdasarkan bobot fitur yang sesuai dengan preferensi pengguna, misalnya Gaming lebih menitikberatkan pada Performance Score, RAM, dan Baterai, sedangkan Photography lebih fokus pada kamera. Skor dihitung dengan menjumlahkan hasil perkalian bobot preferensi dengan nilai fitur masing-masing smartphone. Setelah skor dihitung, smartphone diurutkan berdasarkan Ranking Score tertinggi untuk menghasilkan daftar rekomendasi terbaik tanpa perlu melibatkan model pembelajaran mesin.
"""

import numpy as np

def calculate_wsm(df_standardized, preference, max_price):
    """
    Menghitung skor rekomendasi berdasarkan metode Weighted Sum Model (WSM) dengan filter harga maksimal.

    Parameters:
    df_standardized (DataFrame): Data smartphone yang telah melalui proses standardisasi menggunakan StandardScaler.
                                 Semua fitur numerik telah dinormalisasi agar memiliki skala yang sebanding.

    preference (str): Preferensi pengguna yang menentukan bobot fitur yang digunakan dalam perhitungan skor WSM.
                      Pilihan yang tersedia:
                      - "gaming": Prioritas pada performa, baterai, dan RAM.
                      - "photography": Prioritas pada kamera belakang, kamera depan, dan ukuran layar.
                      - "normal usage": Prioritas pada kenyamanan penggunaan sehari-hari seperti bobot ringan, daya tahan baterai, dan performa seimbang.

    max_price (float): Batas maksimal harga smartphone yang dipilih oleh pengguna.

    Returns:
    DataFrame: Data smartphone yang telah dihitung skor WSM-nya, difilter berdasarkan harga,
               dan diurutkan dari skor tertinggi ke terendah.
    """

    if preference not in weight_preferences:
        raise ValueError("Preferensi tidak valid. Pilih dari: 'gaming', 'photography', atau 'normal usage'.")

    # Sort By Price
    df_filtered = df_standardized[df_standardized["Launched Price (China/CNY)"] <= max_price].copy()

    if df_filtered.empty:
        return "Tidak ada smartphone yang sesuai dengan preferensi dan batas harga yang diberikan."

    # Get Weight Preferences
    weights = weight_preferences[preference]

    # Inverse Mobile Weight (g) karena semakin ringan semakin baik
    df_filtered["Mobile Weight (g)"] = 1 / (df_filtered["Mobile Weight (g)"] + 1e-9)

    # Count WSM Score
    df_filtered["WSM Score"] = np.dot(df_filtered[list(weights.keys())], list(weights.values()))

    # Sort by highest score
    df_filtered = df_filtered.sort_values(by="WSM Score", ascending=False)

    return df_filtered

"""Diatas adalah Model untuk menghitung WSM Score berdasarkan preferensi smartphone dan harga maksimal dari pengguna.

## Model 2: Learning to Rank (LTR)
Learning to Rank (LTR) adalah teknik dalam Machine Learning yang digunakan untuk mengurutkan item berdasarkan relevansi terhadap kueri atau preferensi tertentu. LTR biasanya digunakan dalam sistem rekomendasi, pencarian informasi (IR), dan ranking hasil pencarian. Dalam sistem rekomendasi smartphone, LTR digunakan untuk mengurutkan smartphone berdasarkan relevansi terhadap preferensi pengguna.

Dalam penerapan Learning to Rank (LTR) pada sistem rekomendasi smartphone, pertama-tama dihitung Ranking Score berdasarkan bobot fitur sesuai preferensi pengguna, misalnya Gaming lebih fokus pada Performance Score, RAM, dan Baterai, sedangkan Photography lebih menitikberatkan pada kamera. Selanjutnya, model Deep Learning dilatih untuk belajar pola ranking dengan menggunakan fitur smartphone sebagai input (X) dan Ranking Score sebagai label ranking (y), sehingga model dapat memprediksi skor relevansi smartphone berdasarkan input pengguna (preferensi & batas harga). Akhirnya, hasil prediksi diurutkan berdasarkan ranking tertinggi untuk menghasilkan rekomendasi terbaik.
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split

# function to calculate score for every preference
def calculate_score(df, preference):
    """
    Menghitung score berdasarkan bobot preferensi.
    """
    weights = weight_preferences[preference]

    # Inversi\e Mobile Weight, more lighter is better
    df["Mobile Weight (g)"] = 1 / (df["Mobile Weight (g)"] + 1e-9)

    df[f"score ({preference})"] = np.dot(df[list(weights.keys())], list(weights.values()))

    return df

# Count all score for every preference
for pref in weight_preferences.keys():
    df = calculate_score(df, pref)

# One-Hot Encoding for preference
preference_encoding = {
    "gaming": [1, 0, 0],
    "photography": [0, 1, 0],
    "normal usage": [0, 0, 1]
}

df_list = []
for pref in weight_preferences.keys():
    df_pref = df.copy()
    df_pref[["gaming", "photography", "normal usage"]] = preference_encoding[pref]
    df_pref["score"] = df_pref[f"score ({pref})"]
    df_list.append(df_pref)

df_ltr = pd.concat(df_list, ignore_index=True)

features = list(weight_preferences["gaming"].keys()) + ["gaming", "photography", "normal usage"]
X = df_ltr[features].values
y = df_ltr["score"].values

# Split data for training & testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)

"""## Result Model 1: Weighted Sum Model (WSM)"""

from scipy.special import boxcox

user_preference = "gaming"
max_price = 2500  # Original price in CNY

# Transform max_price using Box-Cox
max_price_transformed = boxcox(max_price, boxcox_lambdas["Launched Price (China/CNY)"])

# Create a dummy array with the same number of features (filled with zeros)
dummy_array = np.zeros((1, len(numerical_features)))

# Replace only the price feature with transformed price
feature_index = numerical_features.index("Launched Price (China/CNY)")
dummy_array[0, feature_index] = max_price_transformed

# Apply StandardScaler transform (only for the price feature)
max_price_standardized = scaler.transform(dummy_array)[0, feature_index]

# Get recommendation using standardized price
df_recommendation = calculate_wsm(df, preference=user_preference, max_price=max_price_standardized)

# Decode Company Name and Model Name using reverse mapping
df_recommendation["Company Name"] = df_recommendation["Company Name Encoded"].map(reverse_company_mapping)
df_recommendation["Model Name"] = df_recommendation["Model Name Encoded"].map(reverse_model_mapping)

columns_order = ["Company Name", "Model Name"] + [col for col in df_recommendation.columns if col not in ["Company Name", "Model Name"]]
df_recommendation = df_recommendation[columns_order]

df_recommendation = df_recommendation.drop(columns=["Company Name Encoded", "Model Name Encoded"])

numerical_features = [
    "Mobile Weight (g)", "RAM (GB)", "Front Camera (MP)", "Back Camera (MP)",
    "Battery Capacity (mAh)", "Screen Size (inches)",
    "Launched Price (China/CNY)", "Performance Score", "Launched Year"
]

df_recommendation.loc[:, numerical_features] = df_original.loc[df_recommendation.index, numerical_features]

df_recommendation.head(10)

"""Diatas adalah hasil rekomendasi Top-10 smartphone untuk preferensi gaming dan harga maksimal 2500 CNY dari model WSM.

## Result Model 2: Learning to Rank (LTR)
"""

from tensorflow.keras.models import load_model
from scipy.special import boxcox
import numpy as np
import pandas as pd

def predict_with_preference(preference, max_price):
    """
    Memprediksi ranking score berdasarkan preferensi pengguna, dengan mempertimbangkan harga maksimal yang telah distandarisasi.
    """
    # Transform max_price
    max_price_transformed = boxcox(max_price, boxcox_lambdas["Launched Price (China/CNY)"])

    dummy_array = np.zeros((1, len(numerical_features)))
    feature_index = numerical_features.index("Launched Price (China/CNY)")
    dummy_array[0, feature_index] = max_price_transformed

    max_price_standardized = scaler.transform(dummy_array)[0, feature_index]

    df_filtered = df[df["Launched Price (China/CNY)"] <= max_price_standardized].copy()

    if df_filtered.empty:
        return "Tidak ada smartphone yang sesuai dengan preferensi dan batas harga."

    df_filtered[["gaming", "photography", "normal usage"]] = preference_encoding[preference]

    X_new = df_filtered[features].values

    df_filtered["Predicted Ranking Score"] = model.predict(X_new)

    # Sort by highest score
    df_sorted = df_filtered.sort_values(by="Predicted Ranking Score", ascending=False)

    # Decode "Company Name" and"Model Name"
    df_sorted["Company Name"] = df_sorted["Company Name Encoded"].map(reverse_company_mapping)
    df_sorted["Model Name"] = df_sorted["Model Name Encoded"].map(reverse_model_mapping)

    selected_columns = ["Company Name", "Model Name", "Predicted Ranking Score", "Launched Price (China/CNY)"]
    df_sorted = df_sorted[selected_columns]

    df_sorted.loc[:, numerical_features] = df_original.loc[df_sorted.index, numerical_features]

    return df_sorted.head(10)

predict_with_preference("gaming", 2500)

"""Diatas adalah hasil rekomendasi Top-10 smartphone untuk preferensi gaming dan harga maksimal 2500 CNY dari model LTR.

# Evaluation
Setelah melakukan pemodelan, langkah selanjutnya adalah evaluasi untuk mengukur seberapa baik sistem dalam memberikan rekomendasi yang sesuai dengan preferensi pengguna.

Evaluasi dilakukan dengan menggunakan metrik **Precision**, yang mengukur sejauh mana rekomendasi yang diberikan oleh sistem sesuai dengan kriteria yang telah ditentukan. Precision mengukur proporsi rekomendasi yang benar-benar relevan dibandingkan dengan jumlah total rekomendasi yang diberikan. Tiap baris dianalisis untuk ditentukan apakah sesuai dengan kriteria apa tidak.

Kriteria yang digunakan untuk menentukan apakah smartphone relevan untuk gaming:
- RAM lebih dari sama dengan 12 GB
- Performance Score lebih dari sama dengan 400.000

Berikut adalah hasil evaluasi berdasarkan percobaan sebelumnya untuk preferensi "gaming" dan harga maksimal "2500" CNY dari setiap model:

### Model 1: Weight Sum Model (WSM)

| Model Name                  | RAM (GB) | Performance Score | WSM Score  | Relevan (Gaming) |
|-----------------------------|---------|------------------|------------|------------------|
| infinix Hot 50 Pro+         | 12.0    | 883658.0         | 1.155704   | ✅               |
| realme P2 Pro 5G 256GB      | 12.0    | 859609.0         | 1.151382   | ✅               |
| infinix Note 40 Pro 5G      | 12.0    | 655239.0         | 0.928939   | ✅               |
| realme P2 Pro 5G 128GB      | 8.0     | 883658.0         | 0.872392   | ❌               |
| infinix Zero 40 5G          | 12.0    | 513284.0         | 0.714008   | ✅               |
| infinix Zero 40             | 12.0    | 513284.0         | 0.714008   | ✅               |
| realme P1 Speed 5G 256GB    | 12.0    | 453448.0         | 0.629236   | ✅               |
| infinix Note 40 Pro         | 12.0    | 453448.0         | 0.621577   | ✅               |
| vivo Y200 GT 128GB         | 12.0    | 412258.0         | 0.547185   | ✅               |
| realme P1 Pro 5G 256GB      | 12.0    | 394463.0         | 0.540680   | ❌               |

Jumlah rekomendasi yang relevan = 8

Jumlah total rekomendasi = 10

**Hasil precission model = 8/10 = 80%**

### Model 2: Learning to Rank (LTR)

| Model Name                  | RAM (GB) | Performance Score | Predicted Ranking Score | Relevan (Gaming) |
|-----------------------------|---------|------------------|-------------------------|------------------|
| realme P2 Pro 5G 256GB      | 12.0    | 859609.0         | 1.169090                | ✅               |
| infinix Hot 50 Pro+         | 12.0    | 883658.0         | 0.946402                | ✅               |
| infinix Note 40 Pro 5G      | 12.0    | 655239.0         | 0.718931                | ✅               |
| realme P1 Speed 5G 256GB    | 12.0    | 453448.0         | 0.655203                | ✅               |
| infinix Zero 40 5G          | 12.0    | 513284.0         | 0.613936                | ✅               |
| infinix Zero 40             | 12.0    | 513284.0         | 0.613936                | ✅               |
| vivo Y200 GT 128GB         | 12.0    | 412258.0         | 0.578339                | ✅               |
| realme P1 Pro 5G 256GB      | 12.0    | 394463.0         | 0.573573                | ❌               |
| realme Neo 7 128GB         | 8.0     | 513284.0         | 0.555282                | ❌               |
| infinix Note 40 Pro         | 12.0    | 453448.0         | 0.538993                | ✅               |

Jumlah rekomendasi yang relevan = 8

Jumlah total rekomendasi = 10

**Hasil precission model = 8/10 = 80%**

### Kesimpulan
- Kedua model sama-sama memiliki precision 80% berdasarkan kriteria yang diberikan. Dengan Precision sebesar 80%, berarti 8 dari 10 rekomendasi yang diberikan sistem benar-benar sesuai dengan kriteria gaming. Meskipun masih ada 2 item yang kurang sesuai, hal ini menunjukkan bahwa model sudah cukup efektif dalam menyaring smartphone yang cocok berdasarkan spesifikasi yang diberikan.
- Kedua model memberikan Top-10 Recommendation yang mirip dengan permintaan yang sama (gaming dan 2500 CNY), tetapi masih ada beberapa item yang berbeda.
- 2 item yang tidak memenuhi kriteria sebenarnya juga masih cukup dekat dengan kriteria sehingga masih cukup relevan sebagai rekomendasi

## Conclusion

Berdasarkan evaluasi menggunakan metrik Precision, kedua model, Weighted Sum Model (WSM) dan Learning to Rank (LTR), mencapai nilai Precision sebesar 80%, menunjukkan bahwa sistem rekomendasi mampu memberikan rekomendasi yang cukup relevan dengan preferensi pengguna. WSM memberikan pendekatan berbasis bobot fitur, sedangkan LTR mampu mengurutkan rekomendasi secara lebih optimal berdasarkan relevansi preferensi.

Dari perspektif Business Understanding, model yang dikembangkan telah menjawab semua problem statement dengan baik:
1. Identifikasi fitur utama yang berpengaruh terhadap pemilihan smartphone berhasil dilakukan, dengan RAM dan skor performa sebagai faktor utama untuk preferensi gaming.
2. Pengolahan dan normalisasi data, termasuk encoding fitur kategorikal, telah meningkatkan kualitas dataset dalam pemodelan rekomendasi.
3. Pembangunan sistem rekomendasi berbasis spesifikasi smartphone berhasil dilakukan menggunakan pendekatan Content-Based Filtering.

Penelitian ini juga berhasil mencapai setiap goals yang ditetapkan:
1. Fitur-fitur relevan telah diidentifikasi dan diekstraksi untuk meningkatkan kualitas rekomendasi.
2. Implementasi model WSM dan LTR berhasil memberikan rekomendasi yang akurat, sesuai dengan preferensi pengguna.
3. Evaluasi dengan Precision menunjukkan bahwa sistem dapat memberikan rekomendasi yang relevan dengan tingkat keakuratan yang baik.

Dampak dari solution statement yang dirancang juga terlihat jelas dalam penelitian ini:
1. Eksplorasi dan preprocessing data berhasil meningkatkan akurasi rekomendasi dengan membersihkan dan menyusun data secara optimal.
2. Pemilihan metode WSM dan LTR membantu dalam perancangan sistem rekomendasi yang mampu menangkap preferensi pengguna secara lebih personal.
3. Evaluasi menggunakan metrik Precision memastikan bahwa sistem tidak hanya memberikan rekomendasi sembarang, tetapi benar-benar relevan dengan kebutuhan pengguna.

Dengan hasil ini, sistem rekomendasi smartphone yang dikembangkan dapat membantu konsumen dalam menemukan smartphone yang sesuai dengan preferensi mereka dengan lebih cepat dan akurat, sehingga mempermudah pengambilan keputusan dalam pembelian.
"""